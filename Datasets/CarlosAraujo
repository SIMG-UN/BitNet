CarlosAraujo
Datasets que me gustaron:
  https://huggingface.co/datasets/uonlp/CulturaX
Dataset enorme con ~6.3 billones de tokens en 167 idiomas, altamente filtrado y limpiado, ideal para preentrenamiento multilingüe de LLMs 
  https://huggingface.co/mcamara/gemma-7b-spanishbillionwords
Corpus de ~1.5 billones (~15 GB comprimido) de palabras en español compiladas a partir de diversos recursos (Wikipedia, Europarl, AnCora, etc.). Textos sin anotación (brutos), bien para hacer pre‑entrenamiento
  https://www.kaggle.com/datasets/felixludos/babel-briefings
Más que todo son noticias, es muy pequeño pero está enfocado en titulares de noticias. Mejor para fine‑tuning en tareas específicas, no para preentrenamiento desde cero.

  



